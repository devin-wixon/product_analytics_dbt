#!/usr/bin/env python3
"""
Generate saved queries YAML for flexible parameterization.

This script creates all combinations of time grains and dimensions
for comprehensive BI exports (ex: Tableau) parameterization while maintaining DRY principles.
"""

import yaml


def get_dimensions():
    """Define all available dimensions for exports with flexible parameterization."""
    return [
        {
            "name": "program_name",
            "label": "Program name",
            "semantic_ref": "program__program_name",
        },
        {
            "name": "resource_type",
            "label": "Resource type",
            "semantic_ref": "resource__resource_type",
        },
        {
            "name": "district_name",
            "label": "District name",
            "semantic_ref": "district__district_name",
        },
        {
            "name": "district_type",
            "label": "District type",
            "semantic_ref": "district__district_type",
        },
        {
            "name": "application_name",
            "label": "Application name",
            "semantic_ref": "event__application_name",
        },
    ]


def get_time_grains():
    """Define all time grains for analysis."""
    return [
        {"name": "day", "semantic_ref": "event__metric_time_day"},
        {"name": "week", "semantic_ref": "event__metric_time_week"},
        {"name": "month", "semantic_ref": "event__metric_time_month"},
    ]


def get_metrics():
    """Define metrics to include in all queries."""
    return ["n_active_users", "n_events"]


def generate_dimension_combinations():
    """Generate all single and 2-way dimension combinations."""
    dimensions = get_dimensions()
    all_combos = []

    # "All" combination (no dimensions)
    all_combo = {
        "id": "all",
        "label": "All (no dimensional breakdown)",
        "dimensions": [],
    }
    all_combos.append(all_combo)

    # Single dimensions
    for dim in dimensions:
        combo = {"id": dim["name"], "label": dim["label"], "dimensions": [dim]}
        all_combos.append(combo)

    # Two-way combinations (fix double underscore issue)
    for i, dim_a in enumerate(dimensions):
        for dim_b in dimensions[i + 1 :]:
            combo = {
                "id": f"{dim_a['name']}_{dim_b['name']}",  # Single underscore due to naming constraints in saved queries
                "label": f"{dim_a['label']} × {dim_b['label']}",
                "dimensions": [dim_a, dim_b],
            }
            all_combos.append(combo)

    return all_combos


def generate_saved_query(time_grain, dimension_combo):
    """Generate a single saved query configuration."""
    metrics = get_metrics()
    query_name = f"sq_{time_grain['name']}_{dimension_combo['id']}"
    export_name = f"qexptbl_{time_grain['name']}_{dimension_combo['id']}"

    # Build group_by list
    group_by = [
        f"TimeDimension('{time_grain['semantic_ref']}', '{time_grain['name']}')"
    ]
    for dim in dimension_combo["dimensions"]:
        group_by.append(f"Dimension('{dim['semantic_ref']}')")

    return {
        "name": query_name,
        "description": f"Metrics by {time_grain['name']} and {dimension_combo['label']}",
        "query_params": {"metrics": metrics, "group_by": group_by},
        "exports": [
            {
                "name": export_name,
                "config": {
                    "export_as": "table",
                    "schema": "{{ 'exports' if target.name == 'prod' else target.schema }}",
                    "alias": export_name,
                },
            }
        ],
    }


def generate_all_saved_queries():
    """Generate all saved query configurations."""
    time_grains = get_time_grains()
    dimension_combos = generate_dimension_combinations()
    all_queries = []

    for time_grain in time_grains:
        for dimension_combo in dimension_combos:
            query = generate_saved_query(time_grain, dimension_combo)
            all_queries.append(query)

    return all_queries


def generate_exports_time_grains_dims_sql():
    """Generate the exports_time_grains_dims.sql model."""
    time_grains = get_time_grains()
    dimension_combos = generate_dimension_combinations()
    metrics = get_metrics()

    sql_lines = []
    sql_lines.append("-- Generated by scripts/generate_saved_queries.py")
    sql_lines.append(
        "-- Purpose: Union all export tables with standardized time grain dimensions for BI parameterization"
    )
    sql_lines.append("")
    sql_lines.append("with")
    sql_lines.append("")

    # Generate CTEs for each export table
    cte_lines = []
    union_lines = []

    for time_grain in time_grains:
        for dimension_combo in dimension_combos:
            export_name = f"qexptbl_{time_grain['name']}_{dimension_combo['id']}"

            # Build the CTE
            cte_lines.append(f"  {export_name} as (")
            cte_lines.append("    select")

            # Use the actual column name pattern with repeated time grain
            cte_lines.append(
                f"      {time_grain['semantic_ref']}__{time_grain['name']} as date_at_time_grain,"
            )

            cte_lines.append(f"      '{time_grain['name']}' as time_grain,")
            cte_lines.append(f"      '{dimension_combo['id']}' as dim_set,")
            cte_lines.append("")

            # Handle dimensions
            if len(dimension_combo["dimensions"]) == 0:
                # "All" case - no dimensions
                cte_lines.append("      'All' as dim_a_label,")
                cte_lines.append("      'All' as dim_a_value,")
                cte_lines.append("      null as dim_b_label,")
                cte_lines.append("      cast(null as varchar) as dim_b_value,")
            elif len(dimension_combo["dimensions"]) == 1:
                # Single dimension
                dim = dimension_combo["dimensions"][0]
                cte_lines.append(f"      '{dim['label']}' as dim_a_label,")
                cte_lines.append(f"      {dim['semantic_ref']} as dim_a_value,")
                cte_lines.append("      null as dim_b_label,")
                cte_lines.append("      cast(null as varchar) as dim_b_value,")
            else:
                # Two dimensions
                dim_a = dimension_combo["dimensions"][0]
                dim_b = dimension_combo["dimensions"][1]
                cte_lines.append(f"      '{dim_a['label']}' as dim_a_label,")
                cte_lines.append(f"      {dim_a['semantic_ref']} as dim_a_value,")
                cte_lines.append(f"      '{dim_b['label']}' as dim_b_label,")
                cte_lines.append(f"      {dim_b['semantic_ref']} as dim_b_value,")

            cte_lines.append("")
            # Add metrics
            for i, metric in enumerate(metrics):
                if i == 0:
                    cte_lines.append(f"      {metric}")
                else:
                    cte_lines.append(f"      , {metric}")

            cte_lines.append("")
            cte_lines.append("    from {{ source('exports', '" + export_name + "') }}")
            cte_lines.append("  ),")
            cte_lines.append("")

            # Add to union
            union_lines.append(f"  select * from {export_name}")

    # Remove the trailing comma from the last CTE
    # Find the last occurrence of "  )," and replace with "  )"
    for i in range(len(cte_lines) - 1, -1, -1):
        if cte_lines[i] == "  ),":
            cte_lines[i] = "  )"
            break

    # Combine CTEs and union
    sql_lines.extend(cte_lines)
    sql_lines.append("")
    sql_lines.append("-- Union all tables")
    for i, union_line in enumerate(union_lines):
        if i == 0:
            sql_lines.append(union_line)
        else:
            sql_lines.append("  union all")
            sql_lines.append(union_line)

    sql_lines.append("")
    return "\n".join(sql_lines)


def main():
    """Generate and save the saved queries YAML file."""
    saved_queries = generate_all_saved_queries()

    output = {"version": 2, "saved_queries": saved_queries}

    # Custom YAML representation for cleaner output
    def represent_none(self, data):
        return self.represent_scalar("tag:yaml.org,2002:null", "")

    yaml.add_representer(type(None), represent_none)

    # Write to file
    output_path = "../models/semantic_models/saved_queries_export_generated.yml"
    with open(output_path, "w") as f:
        f.write("# Generated by scripts/generate_saved_queries.py\n")
        f.write(
            "# Purpose: Dynamically generated saved queries for Bi export (ex: Tableau) parameterization\n"
        )
        f.write(
            f"# Generates {len(saved_queries)} queries for all time grains × dimension combinations\n\n"
        )
        yaml.dump(output, f, default_flow_style=False, sort_keys=False, width=1000)

    print(f"Generated {len(saved_queries)} saved queries in {output_path}")

    # Generate sources YAML
    time_grains = get_time_grains()
    dimension_combos = generate_dimension_combinations()

    sources_tables = []

    # Generate exports for all combinations (including "all")
    for time_grain in time_grains:
        for dimension_combo in dimension_combos:
            export_name = f"qexptbl_{time_grain['name']}_{dimension_combo['id']}"
            sources_tables.append({"name": export_name})

    sources_output = {
        "version": 2,
        "sources": [
            {
                "name": "exports",
                "schema": "{{ 'exports' if target.name == 'prod' else target.schema }}",
                "description": "Tables exported from dbt semantic layer saved queries, used as a source for unioning to create performant BI models.",
                "tables": sources_tables,
            }
        ],
    }

    sources_path = "../models/staging/query_exports/_sources_semantic_exports.yml"
    with open(sources_path, "w") as f:
        f.write("# Generated by scripts/generate_saved_queries.py\n\n")
        yaml.dump(
            sources_output, f, default_flow_style=False, sort_keys=False, width=1000
        )

    print(f"Generated sources file with {len(sources_tables)} tables in {sources_path}")

    # Generate exports_time_grains_dims.sql
    exports_sql = generate_exports_time_grains_dims_sql()
    exports_sql_path = (
        "../models/marts/bi_sl_exports_as_sources/exports_time_grains_dims.sql"
    )

    with open(exports_sql_path, "w") as f:
        f.write(exports_sql)

    print(f"Generated exports_time_grains_dims.sql in {exports_sql_path}")


if __name__ == "__main__":
    main()
